{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data and turn into np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>...</th>\n",
       "      <th>Ecstasy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>legalh</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>Semer</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1884.0</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1885.0</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1886.0</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1887.0</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1888.0</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      Age   Gender  Education  Country  Ethnicity  Neuroticism  \\\n",
       "0        1.0  0.49788  0.48246   -0.05921  0.96082    0.12600      0.31287   \n",
       "1        2.0 -0.07854 -0.48246    1.98437  0.96082   -0.31685     -0.67825   \n",
       "2        3.0  0.49788 -0.48246   -0.05921  0.96082   -0.31685     -0.46725   \n",
       "3        4.0 -0.95197  0.48246    1.16365  0.96082   -0.31685     -0.14882   \n",
       "4        5.0  0.49788  0.48246    1.98437  0.96082   -0.31685      0.73545   \n",
       "...      ...      ...      ...        ...      ...        ...          ...   \n",
       "1880  1884.0 -0.95197  0.48246   -0.61113 -0.57009   -0.31685     -1.19430   \n",
       "1881  1885.0 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685     -0.24649   \n",
       "1882  1886.0 -0.07854  0.48246    0.45468 -0.57009   -0.31685      1.13281   \n",
       "1883  1887.0 -0.95197  0.48246   -0.61113 -0.57009   -0.31685      0.91093   \n",
       "1884  1888.0 -0.95197 -0.48246   -0.61113  0.21128   -0.31685     -0.46725   \n",
       "\n",
       "      Extraversion  Openness  Agreeableness  ...   Ecstasy  Heroin  Ketamine  \\\n",
       "0         -0.57545  -0.58331       -0.91699  ...       0.0     0.0       0.0   \n",
       "1          1.93886   1.43533        0.76096  ...       1.0     0.0       0.0   \n",
       "2          0.80523  -0.84732       -1.62090  ...       0.0     0.0       0.0   \n",
       "3         -0.80615  -0.01928        0.59042  ...       0.0     0.0       0.0   \n",
       "4         -1.63340  -0.45174       -0.30172  ...       0.0     0.0       0.0   \n",
       "...            ...       ...            ...  ...       ...     ...       ...   \n",
       "1880       1.74091   1.88511        0.76096  ...       0.0     0.0       0.0   \n",
       "1881       1.74091   0.58331        0.76096  ...       0.0     0.0       0.0   \n",
       "1882      -1.37639  -1.27553       -1.77200  ...       1.0     0.0       0.0   \n",
       "1883      -1.92173   0.29338       -1.62090  ...       1.0     0.0       0.0   \n",
       "1884       2.12700   1.65653        1.11406  ...       1.0     0.0       0.0   \n",
       "\n",
       "      legalh  LSD  Meth  Mushrooms  Nicotine  Semer  VSA  \n",
       "0        0.0  0.0   0.0        0.0       0.0    0.0  0.0  \n",
       "1        0.0  0.0   1.0        0.0       1.0    0.0  0.0  \n",
       "2        0.0  0.0   0.0        0.0       0.0    0.0  0.0  \n",
       "3        0.0  0.0   0.0        0.0       0.0    0.0  0.0  \n",
       "4        0.0  0.0   0.0        0.0       0.0    0.0  0.0  \n",
       "...      ...  ...   ...        ...       ...    ...  ...  \n",
       "1880     1.0  1.0   0.0        0.0       0.0    0.0  1.0  \n",
       "1881     1.0  1.0   1.0        1.0       1.0    0.0  0.0  \n",
       "1882     0.0  0.0   0.0        0.0       1.0    0.0  0.0  \n",
       "1883     1.0  1.0   0.0        1.0       1.0    0.0  0.0  \n",
       "1884     1.0  1.0   0.0        1.0       1.0    0.0  0.0  \n",
       "\n",
       "[1885 rows x 32 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"drugConsumption_BinaryResponse.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'float32' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3388199a000e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'float32' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame.to_numpy(data)\n",
    "n,p = data.shape\n",
    "data.astype(\"float32\")\n",
    "print(data.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1885, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = data[:,1:13]\n",
    "predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1885, 19)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = data[:,13:]\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0000e+00 -7.8540e-02 -4.8246e-01 ...  1.0000e+00  0.0000e+00\n",
      "   0.0000e+00]\n",
      " [ 3.0000e+00  4.9788e-01 -4.8246e-01 ...  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00]\n",
      " [ 4.0000e+00 -9.5197e-01  4.8246e-01 ...  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00]\n",
      " ...\n",
      " [ 1.8860e+03 -7.8540e-02  4.8246e-01 ...  1.0000e+00  0.0000e+00\n",
      "   0.0000e+00]\n",
      " [ 1.8870e+03 -9.5197e-01  4.8246e-01 ...  1.0000e+00  0.0000e+00\n",
      "   0.0000e+00]\n",
      " [ 1.8880e+03 -9.5197e-01 -4.8246e-01 ...  1.0000e+00  0.0000e+00\n",
      "   0.0000e+00]]\n",
      "[[ 1.00000e+00  4.97880e-01  4.82460e-01 ...  0.00000e+00  0.00000e+00\n",
      "   0.00000e+00]\n",
      " [ 8.00000e+00  4.97880e-01 -4.82460e-01 ...  0.00000e+00  0.00000e+00\n",
      "   0.00000e+00]\n",
      " [ 9.00000e+00  4.97880e-01  4.82460e-01 ...  1.00000e+00  0.00000e+00\n",
      "   0.00000e+00]\n",
      " ...\n",
      " [ 1.87500e+03 -9.51970e-01 -4.82460e-01 ...  1.00000e+00  0.00000e+00\n",
      "   1.00000e+00]\n",
      " [ 1.87800e+03  2.59171e+00 -4.82460e-01 ...  0.00000e+00  0.00000e+00\n",
      "   0.00000e+00]\n",
      " [ 1.88000e+03 -7.85400e-02 -4.82460e-01 ...  0.00000e+00  0.00000e+00\n",
      "   0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# split training and testing(1/4 for testing)\n",
    "testn = int(n*0.25)\n",
    "trainN = n-testn\n",
    "#print(trainN)\n",
    "# indices for test set\n",
    "indtest = np.random.choice(n,testn,replace=False)\n",
    "#print(len(indtest))\n",
    "traindata = np.zeros((trainN,p))\n",
    "testdata = np.zeros((testn,p))\n",
    "testi = 0\n",
    "traini = 0\n",
    "for i in range(n):\n",
    "    if i in indtest:\n",
    "        testdata[testi] = data[i,:]\n",
    "        testi += 1\n",
    "    else:\n",
    "        traindata[traini] = data[i,:]\n",
    "        traini += 1\n",
    "    #if \n",
    "    if traini > trainN:\n",
    "        print(testi)\n",
    "        \n",
    "print(traindata)\n",
    "print(testdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Dataset/loader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class drugData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.n = data.shape[0]\n",
    "        self.x = torch.from_numpy(data[:,1:13])\n",
    "        #print(self.x.dtype)\n",
    "        self.y = torch.from_numpy(data[:,13:])\n",
    "        \n",
    "        self.x,self.y = self.x.type(torch.DoubleTensor), self.y.type(torch.DoubleTensor)\n",
    "\n",
    "        #print(self.x.dtype)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "trainDataset = drugData(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "torch.Size([19])\n",
      "1414\n"
     ]
    }
   ],
   "source": [
    "trainDataset = drugData(traindata)\n",
    "print(trainDataset[0][0].shape)\n",
    "print(trainDataset[0][1].shape)\n",
    "print(len(traindata))\n",
    "#print(traindata[0][0].dytpe)\n",
    "testDataset = drugData(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainDataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testDataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 12\n",
    "outd = 19\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, hlayer):\n",
    "        super(Model, self).__init__()\n",
    "        self.lin1 = nn.Linear(ind, hlayer)\n",
    "        self.lin2 = nn.Linear(hlayer, outd)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a1 = torch.relu(self.lin1(x))\n",
    "        a2 = torch.sigmoid(self.lin2(a1))\n",
    "        return a2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5698, 0.4264, 0.4591, 0.5216, 0.4876, 0.5253, 0.4706, 0.4245, 0.5161,\n",
       "        0.5862, 0.5157, 0.5102, 0.4350, 0.6571, 0.4869, 0.4923, 0.5508, 0.5924,\n",
       "        0.5167], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugnet = Model(32)\n",
    "drugnet(trainDataset[0][0].float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs = 50,p = True, pinterval = 1):\n",
    "    lossList = []\n",
    "    for i in range(epochs):\n",
    "        runningLoss = 0\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(x.float())\n",
    "            loss = criterion(yhat.float(), y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            runningLoss += loss.item()\n",
    "        if p == True:\n",
    "            if i % pinterval == 0:\n",
    "                print('epoch ', i, ' loss: ', str(runningLoss))\n",
    "        lossList.append(runningLoss)\n",
    "    return lossList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  loss:  12.679917007684708\n",
      "epoch  200  loss:  12.593414008617401\n",
      "epoch  400  loss:  12.459911659359932\n",
      "epoch  600  loss:  12.536751747131348\n",
      "epoch  800  loss:  12.511132284998894\n",
      "epoch  1000  loss:  12.515483796596527\n",
      "epoch  1200  loss:  12.436059087514877\n",
      "epoch  1400  loss:  12.321629837155342\n",
      "epoch  1600  loss:  12.241460904479027\n",
      "epoch  1800  loss:  12.213866487145424\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(drugnet.parameters(), lr=0.03)\n",
    "results = train(drugnet,criterion,optimizer,2000,pinterval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        -1.,  0.,  0.,  0.,  0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testAccuracy(data, model,p= True):\n",
    "    for i in range(len(data)):\n",
    "        with torch.no_grad():\n",
    "            yhat = model(data[i][0].float())\n",
    "        yhat = torch.round(yhat)\n",
    "        y = data[i][1]\n",
    "        #print(\"y\", y)\n",
    "        #print(\"yhat\", yhat)\n",
    "        return(yhat,y)\n",
    "        break\n",
    "yhat, y = testAccuracy(trainDataset,drugnet)\n",
    "yhat - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAccuracy(dloader,model,p = False):\n",
    "    totcount = 0\n",
    "    correctcount = 0\n",
    "    for x,y in dloader:\n",
    "        with torch.no_grad():\n",
    "            yhat = model(x)\n",
    "        yhat = torch.round(yhat)\n",
    "        for i,j in zip(yhat,y):\n",
    "            if i.item() == j.item():\n",
    "                correctcount +=1\n",
    "            totcount += 1\n",
    "    if p == True:\n",
    "        print(correctcount)\n",
    "        print(totcount)\n",
    "    return correctcount/totcount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytochJN",
   "language": "python",
   "name": "pytochjn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
